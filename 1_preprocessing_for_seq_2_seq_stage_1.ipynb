{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e84a0f9-5a14-4bf3-8300-1a00ede1187e",
   "metadata": {},
   "source": [
    "Let's do all preprocessing required for fitting the seq-2-seq model here. We need to extract features for the subwindows. We also need to write generic code incase we need to do changes later depending on the performance of the seq-2-seq model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616077b5-ba8f-46ef-ae05-cd5678282f11",
   "metadata": {},
   "source": [
    "For the seq-2-seq model, we do not have to touch the densities, and as the first step we should extract the features from each subwindow using the fine-tuned model. We still might need the densities later for the latent AR proces part, we will get there in stage 2. We will need to arange the subwindows in a stack though, so that the features could be extracted. We ahve done this sort of work in AR models, we will look into that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53cbc96-2c1f-4a3a-bc7c-05331d3f5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 17:43:18.427889: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-03 17:43:19.976304: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-03 17:43:19.976365: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-03 17:43:20.236663: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-03 17:43:20.679512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0253bd75-d1fe-454f-9cbf-6409ae3fec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648523ca-6428-4a5d-9ba8-ecadd994a1c2",
   "metadata": {},
   "source": [
    "##### Train and Validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c740c-cd95-4953-921d-63f6060b3a90",
   "metadata": {},
   "source": [
    "Let's first focus on train and validation data. Meaning blocks 101, 102, 203, 301, and 204. We will preprocess data required for seq-2-seq model, we do not have to worry currently about the stage 2 (densities). But how are we going to evaluate the seq-2-seq model? should we do that on the rest of the blocks? Therefore we might have to preprocess the test data too. Let's get block 0101 as the example, develop all functions for this, and work on preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f230aa6-0a71-441a-b4b3-bfc596e77fe1",
   "metadata": {},
   "source": [
    "For train data, we need to prepare our final input data in the shape None, 13, 32, and the target data by None, 7, 32. For this, we need to use the fin-tuned model to extract the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea9611-691c-469a-8bda-a96b2a8bee6d",
   "metadata": {},
   "source": [
    "We will also keep pasting the generic functions here, the ones we can use to preprocess the data easily for all the blocks below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870eb5f-0e87-4a06-aad7-083a963cc1ff",
   "metadata": {},
   "source": [
    "##### Block 0101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd5e481-313e-45cb-bd3f-2e2bebcc2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the images and the correct xml files\n",
    "\n",
    "blk_0101_data_path = '../../Spring_2024/S_lab_TasselNet/Block_3_TN/Block_3_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaff8d23-2f80-412b-8f9c-fb1a83e2f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_here = os.listdir(blk_0101_data_path)\n",
    "only_images = [file for file in content_here if file.split(\".\")[-1] == 'jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c7d1666-16bb-40be-968e-9be135e6542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(only_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27040db-2500-44b1-846c-28ee3cf2c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, at the end how do we need the data look like? - None, 13, 32\n",
    "\n",
    "# What do we use for this? We use the images we have - let's only pich the horizontal images out of the lot of files we have at the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3030d08-2947-489c-b6b4-ea827e2e8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_image_list = ['2020_08_03', '2020_08_04', '2020_08_06', '2020_08_07', '2020_08_11', '2020_08_12', '2020_08_14', '2020_08_15', '2020_08_17', '2020_08_18', '2020_08_19', '2020_08_21', '2020_08_25', '2020_08_26', '2020_08_27', '2020_08_28', '2020_08_31', '2020_09_02', '2020_09_07', '2020_09_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55259693-4067-4738-befd-956be8f07fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(horizontal_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04593fc0-d36b-4fa4-895a-d5786f2398c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020_07_22'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_images[0].split('.')[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f7db52-4c91-4356-b20f-58c5776955ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0101_horizontal_images = [file for file in only_images if file.split('.')[0][-10:] in horizontal_image_list]\n",
    "# sort these files according to date\n",
    "blk_0101_horizontal_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad26b4d-e3fa-4012-ae95-e0b43cc720e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blk_0101_horizontal_images\n",
    "len(blk_0101_horizontal_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ff7f33-cb49-4b7c-8992-04e122160801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for extracting onlt the horizontal images out of all the files in the location\n",
    "\n",
    "def get_horizontal_images(file_path):\n",
    "    # get all contents at the file path\n",
    "    all_files = os.listdir(file_path)\n",
    "    # get only the image files as we do not need the xml files for the seq2seq model\n",
    "    only_images = [file for file in all_files if file.split(\".\")[-1] == 'jpeg']\n",
    "    # from all the images only choose the horizontal ones\n",
    "    horizontal_images = [file for file in only_images if file.split('.')[0][-10:] in horizontal_image_list]\n",
    "    # sort the list\n",
    "    horizontal_images.sort()\n",
    "    # return the image list\n",
    "    return horizontal_images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7066faa3-3d43-4976-819c-12d0c2120e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out the function\n",
    "blk_0101_horizontal_image_files = get_horizontal_images(blk_0101_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81dd9033-114e-497b-a986-7ef1aab13c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blk_0101_horizontal_image_files\n",
    "len(blk_0101_horizontal_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f6823f-aa48-44d8-b2a7-ee999d2e6ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function seem to work\n",
    "# sanity check\n",
    "np.mean(blk_0101_horizontal_images == blk_0101_horizontal_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaeddb-6b12-4de2-8151-e7f78622dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, what now? We can write a function for extracting features below - we might want to think how exactly we need to stack the contents\n",
    "# but notice that we do not want to store the subwindow (32,32,3) at all, and can just use the model.predict function to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab9204f-fb3c-4b05-a84b-435008b5143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 17:44:28.554649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# load the finetuned gmp model\n",
    "gmp_model = tf.keras.models.load_model('../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ad02d6-e917-48a9-a60c-fa446b1f1037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5215147-2d76-4d9f-ae92-f6dfb7aaac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature extractor\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = gmp_model.input\n",
    "\n",
    "# feature extractor output - do this at the ReLu activation layer - as this will give the same features as the dropout layer (It does not matter if it is the dropout or the activation layer, the extracted features will be the same)\n",
    "feat_ext_output = gmp_model.layers[-4].output\n",
    "\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b5503d5-6e6a-4f39-b5aa-98963f123d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6612d9bc-51f7-47b2-b11e-0b57edb61360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read one horizontal image\n",
    "joined_im_path = os.path.join(blk_0101_data_path, blk_0101_horizontal_image_files[0])\n",
    "# load the image and the count numpy files\n",
    "loaded_im_file = plt.imread(joined_im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8168b5a-ed72-4be5-b875-2d33bb27ad6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_im_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e14776-9a1d-404d-97c4-3756273a0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_window = loaded_im_file[0: 0 + 300, 0 : 0 + 300,:]\n",
    "sub_window = resize(sub_window, (300, 300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab32d633-0675-417d-8d63-136cd3b7b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_window = np.expand_dims(sub_window, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f4435f7-47d4-4bc7-91ee-b52d534eb8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 300, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_window.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df7a399-f4c1-4dd2-afa3-cf75c3588da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 17:44:31.005361: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "# try prediction from the feature extractor\n",
    "try_predict = feature_extractor_model.predict(sub_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991259e2-9aa8-41a7-9903-53f504a355ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9c880e9-2186-4c19-884b-98fb3aa2f19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.10059818, 0.        , 0.07901728,\n",
       "        0.        , 0.        , 0.        , 0.03111649, 0.08963878,\n",
       "        0.        , 0.        , 0.10756746, 0.        , 0.14078043,\n",
       "        0.        , 0.03288424, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09947642, 0.11643474, 0.        ,\n",
       "        0.03223047, 0.        , 0.06245986, 0.07843374, 0.        ,\n",
       "        0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d02758fa-8ae0-4bf4-867e-d1e2218a35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_window_alt = loaded_im_file[0: 0 + 300, 0 : 0 + 300,:]\n",
    "sub_window_alt = resize(sub_window_alt, (300, 300,3))\n",
    "sub_window_alt = sub_window_alt[None,  ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2483c387-02f2-4d3c-a7fc-1f8382391d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 300, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_window_alt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "760f6038-a845-4b9f-8811-670ea334183c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sub_window == sub_window_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1572c0d0-eaa7-484e-aa4c-5f9bcc9d9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subwindows_and_counts(im_folder_loc, image_name, conv_map, save_folder_name, stride = 300, kernel_size = 300):\n",
    "    im_name = image_name + '.jpeg'\n",
    "    joined_im_path = os.path.join(im_folder_loc, im_name)\n",
    "    # load the image and the count numpy files\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "        \n",
    "    # create the subwindows and counts as follows\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "    \n",
    "    density_sums = []\n",
    "    catch_sub_image_name = []\n",
    "    catch_dense_name = []\n",
    "    sub_image_shapes = []\n",
    "    sub_count_shapes = []\n",
    "    counter = 0\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (300, 300,3))\n",
    "            sub_image_shapes.append(sub_window.shape)\n",
    "            # save the sub window? \n",
    "            sub_window_name = image_name + '_' + str(counter) + '.npy'\n",
    "            save_subwindow_path = save_folder_name + '/' + sub_window_name\n",
    "            np.save(save_subwindow_path, sub_window)\n",
    "            catch_sub_image_name.append(sub_window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419fef6-9dba-428c-9b49-33f9178cd7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336202a-8895-4c8f-b21c-6d8133765ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
