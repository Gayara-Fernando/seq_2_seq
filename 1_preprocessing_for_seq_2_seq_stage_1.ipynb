{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e84a0f9-5a14-4bf3-8300-1a00ede1187e",
   "metadata": {},
   "source": [
    "Let's do all preprocessing required for fitting the seq-2-seq model here. We need to extract features for the subwindows. We also need to write generic code incase we need to do changes later depending on the performance of the seq-2-seq model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616077b5-ba8f-46ef-ae05-cd5678282f11",
   "metadata": {},
   "source": [
    "For the seq-2-seq model, we do not have to touch the densities, and as the first step we should extract the features from each subwindow using the fine-tuned model. We still might need the densities later for the latent AR proces part, we will get there in stage 2. We will need to arange the subwindows in a stack though, so that the features could be extracted. We ahve done this sort of work in AR models, we will look into that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53cbc96-2c1f-4a3a-bc7c-05331d3f5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0253bd75-d1fe-454f-9cbf-6409ae3fec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648523ca-6428-4a5d-9ba8-ecadd994a1c2",
   "metadata": {},
   "source": [
    "##### Train and Validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c740c-cd95-4953-921d-63f6060b3a90",
   "metadata": {},
   "source": [
    "Let's first focus on train and validation data. Meaning blocks 101, 102, 203, 301, and 204. We will preprocess data required for seq-2-seq model, we do not have to worry currently about the stage 2 (densities). But how are we going to evaluate the seq-2-seq model? should we do that on the rest of the blocks? Therefore we might have to preprocess the test data too. Let's get block 0101 as the example, develop all functions for this, and work on preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f230aa6-0a71-441a-b4b3-bfc596e77fe1",
   "metadata": {},
   "source": [
    "For train data, we need to prepare our final input data in the shape None, 13, 32, and the target data by None, 7, 32. For this, we need to use the fin-tuned model to extract the data. To extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500635bd-bc32-46c3-9672-c4fdef3c14f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5e481-313e-45cb-bd3f-2e2bebcc2723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff8d23-2f80-412b-8f9c-fb1a83e2f4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_with_py38_gpu_29)",
   "language": "python",
   "name": "tf_with_py38_gpu_29"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
