{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceea3780-f7c5-440f-98af-3672da4b8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:06:50.284485: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 10:06:50.524116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 10:06:50.524175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 10:06:50.573235: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 10:06:50.650120: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a199cc95-af00-4158-801b-eb41a84dd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the train and validation data\n",
    "all_train_data = os.listdir(\"seq_2_seq_train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5054dbd5-a659-45a4-9ded-13565b4f9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the inputs and targets separated\n",
    "all_train_input_files = [file for file in all_train_data if file.split('.')[0][-14:] == 'input_features']\n",
    "all_train_target_files = [file for file in all_train_data if file.split('.')[0][-15:] == 'target_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b8c827-11df-44bf-9b28-c9b8578f5bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block_0101_extracted_input_features.npy',\n",
       " 'block_0102_extracted_input_features.npy',\n",
       " 'block_0203_extracted_input_features.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_input_files.sort()\n",
    "all_train_input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21030158-2dfa-4339-a349-9e4bf58382aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block_0101_extracted_target_features.npy',\n",
       " 'block_0102_extracted_target_features.npy',\n",
       " 'block_0203_extracted_target_features.npy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_target_files.sort()\n",
    "all_train_target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd24228-4960-409e-850b-31c0665129c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "loaded_all_train_input_files = [np.load(os.path.join(\"seq_2_seq_train_data\", file)) for file in all_train_input_files]\n",
    "loaded_all_train_target_files = [np.load(os.path.join(\"seq_2_seq_train_data\", file)) for file in all_train_target_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8dfd07-7a8d-4984-9772-717520fc2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the files in the list\n",
    "X_train = np.vstack(loaded_all_train_input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1666a1-1135-4e4f-ad41-9fc065f69fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2730, 13, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11808c0c-a01f-4abb-b2c3-f332023d118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.vstack(loaded_all_train_target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "963e0e71-a5f1-4521-b8f0-dd12c7bcf2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2730, 7, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "965aa1fa-4ba1-4ef2-8fb3-f4e5bfb30bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:07:02.429537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 32)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['input_1[0][0]']             \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59936 (234.12 KB)\n",
      "Trainable params: 59936 (234.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "def create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps):\n",
    "    # Input layer for the encoder\n",
    "    inputs = tf.keras.layers.Input(shape=(input_timesteps, input_features))\n",
    "\n",
    "    # Encoder LSTM\n",
    "    encoder = tf.keras.layers.LSTM(64, activation='relu', return_state=True, return_sequences=False)\n",
    "    encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "    # Decoder LSTM: We now provide the encoder's state and initialize it with the encoder's final states\n",
    "    # We reshape the output of the encoder to make sure it is in the expected form for the decoder\n",
    "    decoder_input = tf.keras.layers.RepeatVector(output_timesteps)(encoder_outputs)\n",
    "\n",
    "    # Decoder LSTM, where the output sequence length is `output_timesteps` (7)\n",
    "    decoder_lstm = tf.keras.layers.LSTM(64, activation='relu', return_sequences=True)\n",
    "    decoder_outputs = decoder_lstm(decoder_input, initial_state=[state_h, state_c])\n",
    "\n",
    "    # Dense layer to predict the next 7 time periods (each with 32 features)\n",
    "    outputs = tf.keras.layers.Dense(input_features)(decoder_outputs)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_timesteps = 13  # 12 time periods\n",
    "input_features = 32   # 32 features per time period\n",
    "output_timesteps = 7  # Predict the next 7 time periods\n",
    "\n",
    "# Create the model\n",
    "model = create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd36a1b-b933-4b21-a1c0-ecaf272247b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:07:06.125163: I external/local_xla/xla/service/service.cc:168] XLA service 0x14a160c8dbd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-04 10:07:06.125199: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100S-PCIE-32GB, Compute Capability 7.0\n",
      "2025-06-04 10:07:06.160703: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-04 10:07:06.249025: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749049626.482196  168195 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 6s 29ms/step - loss: 0.1656\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1035\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.1022\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 2s 28ms/step - loss: 0.1015\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1008\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1010\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1003\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1007\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0995\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0994\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0989\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.0991\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0990\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0982\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0982\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0977\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0971\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0975\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0971\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0970\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0963\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0963\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0960\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0959\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0957\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0957\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0958\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0955\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0951\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14a1a4f40ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
