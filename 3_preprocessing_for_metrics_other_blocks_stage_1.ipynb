{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cc1f0d-af14-41fd-85e6-a0a75ff8696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 19:13:21.354522: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-06 19:13:21.391855: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-06 19:13:21.391878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-06 19:13:21.392687: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-06 19:13:21.398451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d6effe-1aba-4368-b6bf-526b8c2e3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49252a86-1f60-4eab-bd9a-197b5fd5d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the fine-tuned model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7e5efe-ed35-4783-b4f9-a00f71172e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 19:13:49.221124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# load the finetuned gmp model\n",
    "gmp_model = tf.keras.models.load_model('../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd433550-20ff-49f1-a45f-bc4f21fe5f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cae73bc-7f5e-4a02-ab56-11cbb729180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature extractor\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = gmp_model.input\n",
    "\n",
    "# feature extractor output - do this at the ReLu activation layer - as this will give the same features as the dropout layer (It does not matter if it is the dropout or the activation layer, the extracted features will be the same)\n",
    "feat_ext_output = gmp_model.layers[-4].output\n",
    "\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e8fffb9-60e8-4bd3-9428-7993e40f543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e9d312-d031-4982-b108-df77c58da122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the previous work, we have the following functions that we have written and can use directly for the work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42b02d5-0ada-42ae-aff8-b13f010be82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for extracting onlt the horizontal images out of all the files in the location\n",
    "\n",
    "def get_horizontal_images(file_path):\n",
    "    # get all contents at the file path\n",
    "    all_files = os.listdir(file_path)\n",
    "    # get only the image files as we do not need the xml files for the seq2seq model\n",
    "    only_images = [file for file in all_files if file.split(\".\")[-1] == 'jpeg']\n",
    "    # from all the images only choose the horizontal ones\n",
    "    horizontal_images = [file for file in only_images if file.split('.')[0][-10:] in horizontal_image_list]\n",
    "    # sort the list\n",
    "    horizontal_images.sort()\n",
    "    # return the image list\n",
    "    return horizontal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8bca3fb-a46c-43c2-a979-e9a68169e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to preprocess all the data for the rest of the blocks, for the task of prediction and performance evaluation.\n",
    "\n",
    "# The problem we currently have is the written code takes up a lot of time. -It takes too much time to do the feature extraction. Currently we are using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c073843a-a22b-43eb-81b0-6fec2559b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following alternate functions are written to improve the execution time of the prediction from the model to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3cc709-f5e6-4d45-8ac2-d676f2f5e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_windows(folder_path, file, stride = 30, kernel_size = 30):\n",
    "    # joined image path\n",
    "    joined_im_path = os.path.join(folder_path, file)\n",
    "    # read the image\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "    # create subwindows and get prediction\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "\n",
    "    # catch all subwindows here\n",
    "    all_subwindows = []\n",
    "    # you can also keep track the subwindows here if required - but let's not worry about that for now\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (kernel_size, kernel_size,3))\n",
    "            # append these to the list\n",
    "            all_subwindows.append(sub_window)\n",
    "            \n",
    "    return all_subwindows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5601bf11-c8f8-4b40-8641-6b89992227ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name, file_path):\n",
    "    # get the subwindows\n",
    "    subwindows = create_sub_windows(file_path, file_name, 30, 30)\n",
    "    # stack the subwindows\n",
    "    stacked_subwindows = np.stack(subwindows, axis = 0)\n",
    "    # print the shape of this\n",
    "    print(stacked_subwindows.shape)\n",
    "    # extract features\n",
    "    extracted_featrues = feature_extractor_model.predict(stacked_subwindows)\n",
    "    \n",
    "    return extracted_featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb036bde-445a-4eb5-9eeb-a4d87060a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images we use in the task are in the following list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf37b311-2de4-4d1f-b41a-593c43d826d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_image_list = ['2020_08_03', '2020_08_04', '2020_08_06', '2020_08_07', '2020_08_11', '2020_08_12', '2020_08_14', '2020_08_15', '2020_08_17', '2020_08_18', '2020_08_19', '2020_08_21', '2020_08_25', '2020_08_26', '2020_08_27', '2020_08_28', '2020_08_31', '2020_09_02', '2020_09_07', '2020_09_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc191f2-b001-405e-89ed-8b1d5f6c6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, let's try and solve this problem with the first block in the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb4b4c2-7151-4b3b-bbe4-2482f727752c",
   "metadata": {},
   "source": [
    "Block 0103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e20dd6-39be-4348-b4dd-2a8fe42932d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0103_data_path = '../../Spring_2024/S_lab_TasselNet/Block_3_TN/Block_3_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0db5226-0f08-4c87-accf-acc2a5c871c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0103_horizontal_images = get_horizontal_images(blk_0103_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd10d3fd-cf76-4b0f-a64e-092756c67673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0103_input_time_point_images = blk_0103_horizontal_images[:13]\n",
    "blk_0103_input_time_point_images.sort()\n",
    "blk_0103_output_time_point_images = blk_0103_horizontal_images[-7:]\n",
    "blk_0103_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6fe5c69-8b34-4d94-9df6-f91d603ff818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0103_input_time_point_images, blk_0103_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aa3da01-fb04-46e8-a577-3842d95c1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now we need to modify the next function a little to see if the timing for the computations can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ae7e35e-105c-40c0-9877-441faf55de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we first stack the subwindows in a function, and then do model.predict may be in a separate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2007374-3de7-442f-85c2-f84f90083b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_windows(folder_path, file, stride = 30, kernel_size = 30):\n",
    "    # joined image path\n",
    "    joined_im_path = os.path.join(folder_path, file)\n",
    "    # read the image\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "    # create subwindows and get prediction\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "\n",
    "    # catch all subwindows here\n",
    "    all_subwindows = []\n",
    "    # you can also keep track the subwindows here if required - but let's not worry about that for now\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (kernel_size, kernel_size,3))\n",
    "            # append these to the list\n",
    "            all_subwindows.append(sub_window)\n",
    "            \n",
    "    return all_subwindows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0314e666-50c9-49ea-9fdd-37838ec47594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10835ae1-cf8b-4ccf-b0f5-70017f5b12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_0 = blk_0103_input_time_point_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ffd49c6-6a87-49aa-8789-0f5aca821309",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_0_sub_windows = create_sub_windows(blk_0103_data_path, test_image_0, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "969aed4e-ab6b-4cf5-a3ea-aa0b0039f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to stack the list\n",
    "test_image_0_sub_windows_stack = np.stack(test_image_0_sub_windows, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701d9165-0d9d-49a6-b9fe-9d9186f8d18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 30, 30, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_0_sub_windows_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eacf764-9a45-4599-9f02-44aebea398f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 19:14:19.271290: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 5ms/step\n",
      "CPU times: user 605 ms, sys: 234 ms, total: 838 ms\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# try model.predict with this\n",
    "test_image_0_extracted_features = feature_extractor_model.predict(test_image_0_sub_windows_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80a00704-ae43-4b64-8670-8653877dbad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_0_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24b5d686-7e20-47d2-a7e6-dea7ce10ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so this happense pretty fast (in 2 seconds as opposed to 42 secods - so we do have a huge improvemet in execution time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "379d423b-433f-4a78-b46d-723c6815f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try doing this for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "939110c4-9a5b-4bc5-80d4-6ae3b8299b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0103_2020_08_03.jpeg',\n",
       " 'Block0103_2020_08_04.jpeg',\n",
       " 'Block0103_2020_08_06.jpeg',\n",
       " 'Block0103_2020_08_07.jpeg',\n",
       " 'Block0103_2020_08_11.jpeg',\n",
       " 'Block0103_2020_08_12.jpeg',\n",
       " 'Block0103_2020_08_14.jpeg',\n",
       " 'Block0103_2020_08_15.jpeg',\n",
       " 'Block0103_2020_08_17.jpeg',\n",
       " 'Block0103_2020_08_18.jpeg',\n",
       " 'Block0103_2020_08_19.jpeg',\n",
       " 'Block0103_2020_08_21.jpeg',\n",
       " 'Block0103_2020_08_25.jpeg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input features for block 0103\n",
    "blk_0103_input_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17f3faac-8820-42e9-a2a8-e442b4c2cfc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.63 s, sys: 206 ms, total: 4.84 s\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "block_0103_extracted_features = []\n",
    "for file in blk_0103_input_time_point_images:\n",
    "    # get the subwindows\n",
    "    subwindows = create_sub_windows(blk_0103_data_path, file, 30, 30)\n",
    "    # stack the subwindows\n",
    "    stacked_subwindows = np.stack(subwindows, axis = 0)\n",
    "    # print the shape of this\n",
    "    print(stacked_subwindows.shape)\n",
    "    # extract features\n",
    "    extracted_featrues = feature_extractor_model.predict(stacked_subwindows)\n",
    "    # append the extracted features\n",
    "    block_0103_extracted_features.append(extracted_featrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccfd181f-e079-4427-be41-aa692eb0f253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_0103_extracted_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1f0e502-58f4-4ba3-bbb2-1a70c4d931e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now stack all these together?\n",
    "blk_0103_stacked_input_features = np.stack(block_0103_extracted_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46ebe1a3-badc-47d9-ac2f-41e77b4c4350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0103_stacked_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ded613d-e6ef-41fa-a56f-0df51723608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, this seems to work really fast - better!\n",
    "# now what if we do a function to get the predictions (extracted features too) - this would be easy for the rest of the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "427af14c-5bec-4b46-bb53-106127a59eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name, file_path):\n",
    "    # get the subwindows\n",
    "    subwindows = create_sub_windows(file_path, file_name, 30, 30)\n",
    "    # stack the subwindows\n",
    "    stacked_subwindows = np.stack(subwindows, axis = 0)\n",
    "    # print the shape of this\n",
    "    print(stacked_subwindows.shape)\n",
    "    # extract features\n",
    "    extracted_featrues = feature_extractor_model.predict(stacked_subwindows)\n",
    "    \n",
    "    return extracted_featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb7a02f3-071c-4d1b-be6e-b5a909e82358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Spring_2024/S_lab_TasselNet/Block_3_TN/Block_3_images_and_xml'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0103_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "478bc6e9-b437-4df8-af70-d55f51feb157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.46 s, sys: 288 ms, total: 4.75 s\n",
      "Wall time: 4.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# see if this works\n",
    "blk_0103_alt_all_features = []\n",
    "for file in blk_0103_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0103_data_path)\n",
    "    blk_0103_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "908d94c2-834b-457e-8bd5-625736310f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_features_stack_0103 = np.stack(blk_0103_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59c3c420-10ba-40cc-9b35-ffac3a4a5a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_features_stack_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8f0b1e7-1aa6-40e7-aace-432a34f61df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if these are the same\n",
    "np.mean(alt_features_stack_0103 == blk_0103_stacked_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23b07a14-403f-477a-bc8f-a0cc22f4e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34708995, 0.34708995)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also let's get the means\n",
    "np.mean(alt_features_stack_0103), np.mean(blk_0103_stacked_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5bb4e7d-230a-4487-90bd-32200e23b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a sanity check here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cde19f12-87a9-422b-9033-c80ac1fa84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What sort of sanity check should we do? Maybe try to track down a few random arrays to ensure the stacking has happened correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2745c0c0-3084-4711-a2fb-df94652c6f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blk_0103_alt_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84de46f7-ab9f-4d06-b6e4-9a5c637f87fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0103_alt_all_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7176d6f2-11a9-4117-bbb5-1bb6ab13e924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "catch_all = []\n",
    "for i in range(len(blk_0103_alt_all_features)):\n",
    "    mean_vec = np.mean(blk_0103_alt_all_features[i] == alt_features_stack_0103[:,i, :])\n",
    "    catch_all.append(mean_vec)\n",
    "    print(mean_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "840cc8e4-ccc2-429e-b1cb-79a7cbc6a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(catch_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "019bd8b6-935c-4895-b7b1-ab6653d8451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this is enough sanity checks. We also checked for output np arrays from both preprocessing methods in notebook 4. Let's just make sure the preprocessing is done correctly for the remainig blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "594dc1ee-7574-4c6d-80e3-5835cb12f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use only the functions we developed above to get the extracted features for block 0103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52841d23-9283-4604-bb5d-686034432c48",
   "metadata": {},
   "source": [
    "Block 0103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78a1f21b-e64a-4142-8029-f3ca78a4b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0103_data_path = '../../Spring_2024/S_lab_TasselNet/Block_3_TN/Block_3_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffce7d1c-5931-4b38-a573-a90a6618d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0103_horizontal_images = get_horizontal_images(blk_0103_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3f36363-0f1c-4369-8974-5934b7b342cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0103_input_time_point_images = blk_0103_horizontal_images[:13]\n",
    "blk_0103_input_time_point_images.sort()\n",
    "blk_0103_output_time_point_images = blk_0103_horizontal_images[-7:]\n",
    "blk_0103_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3deb85d-b65f-4954-96fb-101ded172eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.48 s, sys: 227 ms, total: 4.71 s\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0103_alt_all_features = []\n",
    "for file in blk_0103_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0103_data_path)\n",
    "    blk_0103_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9a16f24-fda9-4548-852b-462e8271c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0103_stacked_extracted_input_features = np.stack(blk_0103_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9eb8e1c2-9310-4559-98aa-c3fa61c7cd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0103_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f443d94-7908-40d8-b425-effa57ebbd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34708995"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0103_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90e72a1a-f4e0-46a3-94c2-cc6499c45bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0103_extracted_input_features.npy\", blk_0103_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc1a8ce7-5867-412d-a752-e775596dd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6d81a49-7c77-4a23-ab9c-3c3a7e7c6fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.45 s, sys: 127 ms, total: 2.58 s\n",
      "Wall time: 2.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0103_targets = []\n",
    "for file in blk_0103_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0103_data_path)\n",
    "    blk_0103_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d6f9c77-43f3-4445-a4c2-c561e7a1be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0103_stacked_extracted_targets = np.stack(blk_0103_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f92d100-0bdb-4c31-8fcb-d57515031ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0103_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36bdf3a6-d8fe-48f3-bf82-de12bbe9f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0103_extracted_target_features.npy\", blk_0103_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2224ee-955c-4c50-9242-e4df11647255",
   "metadata": {},
   "source": [
    "Block 0104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d2dc386-55d4-41da-9e0c-ab846ff329ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0104_data_path = '../../Spring_2024/S_lab_TasselNet/Block_4_TN/Block_4_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baa1cefd-2ef8-4e1e-8c60-e31516418e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0104_horizontal_images = get_horizontal_images(blk_0104_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cafaee57-8c3b-4db0-a85a-6624fd01e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0104_input_time_point_images = blk_0104_horizontal_images[:13]\n",
    "blk_0104_input_time_point_images.sort()\n",
    "blk_0104_output_time_point_images = blk_0104_horizontal_images[-7:]\n",
    "blk_0104_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8d3d592e-a5d5-49f5-b518-139a9525b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0104_input_time_point_images, blk_0104_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83d8c420-c6b1-4e28-82ea-e75a427c1b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.55 s, sys: 258 ms, total: 4.8 s\n",
      "Wall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0104_alt_all_features = []\n",
    "for file in blk_0104_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0104_data_path)\n",
    "    blk_0104_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0395358-ea2d-489f-a1a5-51043b3d14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0104_stacked_extracted_input_features = np.stack(blk_0104_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6f003ce-782a-4cdb-915b-4cb6865f960f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0104_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1cfbc11a-04af-4ff0-afba-25dc38406a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38871154"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0104_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b1fbd3c-eab7-4ca9-912e-77bd9df31ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0104_extracted_input_features.npy\", blk_0104_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c369b2fb-d55c-4e41-a441-be6bd777e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c99f5c3-3c07-464f-aab2-56a62ee4b59a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.48 s, sys: 125 ms, total: 2.6 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0104_targets = []\n",
    "for file in blk_0104_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0104_data_path)\n",
    "    blk_0104_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "600d0cc2-42b8-4c73-af4e-54a7223ff90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0104_stacked_extracted_targets = np.stack(blk_0104_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57835bb7-e645-4c74-8e69-bae36e402d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0104_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b37ae199-ee52-4471-9ae5-40a62788bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0104_extracted_target_features.npy\", blk_0104_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a11a8-9703-4301-9d6f-be7178d8963e",
   "metadata": {},
   "source": [
    "Block 0105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6026a94e-6996-4b0c-8123-f848ec76e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0105_data_path = '../../Spring_2024/S_lab_TasselNet/Block_5_TN/Block_5_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "489a5811-ded7-4a67-93ba-45a2c9ff338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0105_horizontal_images = get_horizontal_images(blk_0105_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44143527-479d-4f84-9fae-c0875432a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0105_input_time_point_images = blk_0105_horizontal_images[:13]\n",
    "blk_0105_input_time_point_images.sort()\n",
    "blk_0105_output_time_point_images = blk_0105_horizontal_images[-7:]\n",
    "blk_0105_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b65deb0-690b-4201-90b1-e19420c5c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0105_input_time_point_images, blk_0105_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5e9bb9a-c6e0-4e4f-9b0d-38c5dcba8eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.59 s, sys: 253 ms, total: 4.84 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0105_alt_all_features = []\n",
    "for file in blk_0105_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0105_data_path)\n",
    "    blk_0105_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c330822a-8c5a-4ec2-b7d5-c6ae0e717f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0105_stacked_extracted_input_features = np.stack(blk_0105_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c16a6aae-849f-4b03-887f-f294715e400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0105_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "345c79fa-0e81-4c86-93a0-363689fc1f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36304483"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0105_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e0c0e2b-3ccd-43d6-8f78-7fc515e9b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0105_extracted_input_features.npy\", blk_0105_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63a22333-5fd4-4add-bffa-66088e8f963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81490760-1dd8-4aff-95d4-5ac4148e916b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.41 s, sys: 160 ms, total: 2.57 s\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0105_targets = []\n",
    "for file in blk_0105_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0105_data_path)\n",
    "    blk_0105_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31e50d02-baa6-42c7-8a83-63290f4f4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0105_stacked_extracted_targets = np.stack(blk_0105_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c394c434-57c1-4beb-a632-7a2742ebae29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0105_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb7dc84f-0978-481e-8b78-b80b216c0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0105_extracted_target_features.npy\", blk_0105_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89abc7e1-801a-4a9e-8c74-db344615b438",
   "metadata": {},
   "source": [
    "Block 0106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6daa862-cc09-47e2-b47f-77b6d42dd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0106_data_path = '../../Spring_2024/S_lab_TasselNet/Block_6_TN/Block_6_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "676ae2f9-b4a1-4162-95bf-e27777e1fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0106_horizontal_images = get_horizontal_images(blk_0106_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ebdb99d7-4e0c-41d2-8125-a718243bcd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0106_input_time_point_images = blk_0106_horizontal_images[:13]\n",
    "blk_0106_input_time_point_images.sort()\n",
    "blk_0106_output_time_point_images = blk_0106_horizontal_images[-7:]\n",
    "blk_0106_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1f46f59-bf30-43f2-b23d-143b286005ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0106_input_time_point_images, blk_0106_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0f138cc-38ff-4abe-8482-43a9a25e0229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.55 s, sys: 251 ms, total: 4.8 s\n",
      "Wall time: 4.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0106_alt_all_features = []\n",
    "for file in blk_0106_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0106_data_path)\n",
    "    blk_0106_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f9226ce-b270-4e44-bacf-a45c04d7349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0106_stacked_extracted_input_features = np.stack(blk_0106_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1022432e-efc0-4c35-a103-4606534284ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0106_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "278bfb80-ef33-4bed-afae-27e1d64dd0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3736453"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0106_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7589d2fe-721b-466a-8f16-a1021fc93647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0106_extracted_input_features.npy\", blk_0106_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87c07bde-098d-4c9c-aa76-dd5c411a95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa3ee8f3-41e1-4ac1-b578-8ceefd118ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.37 s, sys: 128 ms, total: 2.49 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0106_targets = []\n",
    "for file in blk_0106_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0106_data_path)\n",
    "    blk_0106_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c32131d-fb70-439e-aeae-20b270e65c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0106_stacked_extracted_targets = np.stack(blk_0106_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c4d2669e-1b8f-4f7c-b143-dfd46c378a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0106_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43876794-20b9-47fc-bb0f-713a950f35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0106_extracted_target_features.npy\", blk_0106_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a3330-b312-4be0-87ac-f6c87c0000a1",
   "metadata": {},
   "source": [
    "Block 0201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "37868f02-81dd-435c-b39a-8598c314fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0201_data_path = '../../Spring_2024/S_lab_TasselNet/Block_7_TN/Block_7_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6aef5f4d-d48c-49e8-af6e-2fe5db615084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0201_horizontal_images = get_horizontal_images(blk_0201_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37e4d422-fa64-4bad-a9e7-8064bc4856d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0201_input_time_point_images = blk_0201_horizontal_images[:13]\n",
    "blk_0201_input_time_point_images.sort()\n",
    "blk_0201_output_time_point_images = blk_0201_horizontal_images[-7:]\n",
    "blk_0201_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ad020fc-92c3-4db2-afb2-4ac9bdc246c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0201_input_time_point_images, blk_0201_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7af49b2-ca08-40d7-bceb-1523b038565a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.48 s, sys: 266 ms, total: 4.75 s\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0201_alt_all_features = []\n",
    "for file in blk_0201_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0201_data_path)\n",
    "    blk_0201_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "653347bd-ecdc-4331-a258-788ccbb08445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0201_stacked_extracted_input_features = np.stack(blk_0201_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae08e44c-924e-4e46-96ea-2497dbb15955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0201_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb39944c-3ef4-46cc-8df5-db9d3cb36c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35994256"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0201_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "273528d9-21a5-4838-999c-da8c1906e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0201_extracted_input_features.npy\", blk_0201_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6a14449b-6bf3-406b-a400-94b095d14991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07942acb-f81d-4ad3-89b2-038b525bf96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.47 s, sys: 148 ms, total: 2.62 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0201_targets = []\n",
    "for file in blk_0201_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0201_data_path)\n",
    "    blk_0201_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7cce7acb-4182-4fd7-a84f-6f657c110ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0201_stacked_extracted_targets = np.stack(blk_0201_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e559e04-a79a-4409-8e68-6d937c06b23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0201_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ccba12b4-934c-43ca-9571-1ae90af1997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0201_extracted_target_features.npy\", blk_0201_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d2ecb-8cbe-40b2-adfe-ff05d597f950",
   "metadata": {},
   "source": [
    "Block 0202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57f2ca0b-e497-4b55-916e-cdf2acd375bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0202_data_path = '../../Spring_2024/S_lab_TasselNet/Block_8_TN/Block_8_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a33aaaa-1058-4c89-bd1c-20ccf898e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0202_horizontal_images = get_horizontal_images(blk_0202_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "24591086-dcfd-43bb-8355-a523bd447f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0202_input_time_point_images = blk_0202_horizontal_images[:13]\n",
    "blk_0202_input_time_point_images.sort()\n",
    "blk_0202_output_time_point_images = blk_0202_horizontal_images[-7:]\n",
    "blk_0202_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1ac56304-eb3c-4a35-ad69-94e8e603d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0202_input_time_point_images, blk_0202_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8ad26a39-f5b3-4594-9099-0a4932a83f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.5 s, sys: 137 ms, total: 4.63 s\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0202_alt_all_features = []\n",
    "for file in blk_0202_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0202_data_path)\n",
    "    blk_0202_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4d7dc700-9de1-47b5-851e-76c9f0eb4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0202_stacked_extracted_input_features = np.stack(blk_0202_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0cc2a7f-cce8-48f4-91ec-17474f6eaf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0202_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "82ddb5d9-de85-458c-9c90-8a4b6c9c22ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3602271"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0202_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "71250ad2-e6a2-44ea-9613-af6ae11e34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0202_extracted_input_features.npy\", blk_0202_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "21fbb683-d345-41c1-8e02-7b67be4e5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e6d7f464-075f-450b-8038-a7019206bc17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.59 s, sys: 132 ms, total: 2.72 s\n",
      "Wall time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0202_targets = []\n",
    "for file in blk_0202_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0202_data_path)\n",
    "    blk_0202_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fa63a917-b858-4a29-ac63-5946eceb0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0202_stacked_extracted_targets = np.stack(blk_0202_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4ed811e0-e2f9-4033-85f9-d20710dee909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0202_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a97d6896-4140-4aee-b0e7-53204fce8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0202_extracted_target_features.npy\", blk_0202_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93a5bd-cc27-4234-a87c-5e506bc7c05e",
   "metadata": {},
   "source": [
    "Block 0205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d2b02edc-59a5-4fe7-a26a-4387109ff25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0205_data_path = '../../Spring_2024/S_lab_TasselNet/Block_11_TN/Block_11_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ac5905cc-99b4-43b8-9d3a-e31cb8cb6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0205_horizontal_images = get_horizontal_images(blk_0205_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "84787d82-e918-40df-af41-0701c44193a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0205_input_time_point_images = blk_0205_horizontal_images[:13]\n",
    "blk_0205_input_time_point_images.sort()\n",
    "blk_0205_output_time_point_images = blk_0205_horizontal_images[-7:]\n",
    "blk_0205_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "04ff9823-f3c4-4534-a97f-dab94a0bbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0205_input_time_point_images, blk_0205_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70f49b95-850c-461a-8f1c-64cd2d437ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.57 s, sys: 221 ms, total: 4.8 s\n",
      "Wall time: 4.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0205_alt_all_features = []\n",
    "for file in blk_0205_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0205_data_path)\n",
    "    blk_0205_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2db600c3-06e5-48e5-b931-ab0711e4ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0205_stacked_extracted_input_features = np.stack(blk_0205_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c524042a-ac1f-4518-a281-785f16a744a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0205_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7914b567-4ef7-46ae-b793-7c8277f10653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37715343"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0205_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d3015d5c-c086-43b0-83bc-541b030f529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0205_extracted_input_features.npy\", blk_0205_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "73465692-4b74-49d6-b1a4-5af0aaf167dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b9c88086-0420-4488-8043-5c64652087a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.4 s, sys: 131 ms, total: 2.53 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0205_targets = []\n",
    "for file in blk_0205_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0205_data_path)\n",
    "    blk_0205_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a37a833-7421-4558-a13b-93662fd32334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0205_stacked_extracted_targets = np.stack(blk_0205_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "33e55885-bdea-499e-ad99-815a407cf630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0205_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "958fcb14-8199-4ff5-a405-02d64c57e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0205_extracted_target_features.npy\", blk_0205_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c692f4-10df-4867-806d-eb6314300926",
   "metadata": {},
   "source": [
    "Block 0206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "58113818-c685-41a9-94ef-692171ce9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0206_data_path = '../../Spring_2024/S_lab_TasselNet/Block_12_TN/Block_12_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "11f24547-e3b5-4069-b4d9-7811391b78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0206_horizontal_images = get_horizontal_images(blk_0206_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "427ed266-71a6-4d4e-9299-9b7b8bec4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0206_input_time_point_images = blk_0206_horizontal_images[:13]\n",
    "blk_0206_input_time_point_images.sort()\n",
    "blk_0206_output_time_point_images = blk_0206_horizontal_images[-7:]\n",
    "blk_0206_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "17510b74-4b94-4631-b0f6-cdce314f5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0206_input_time_point_images, blk_0206_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8709d10c-1a7e-4c7e-b1a0-f4ba278b5712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "CPU times: user 4.62 s, sys: 212 ms, total: 4.83 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0206_alt_all_features = []\n",
    "for file in blk_0206_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0206_data_path)\n",
    "    blk_0206_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "211d4065-adab-4d28-8f4f-9c78131c8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0206_stacked_extracted_input_features = np.stack(blk_0206_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "522c3e0c-468d-4dff-b000-b79d7c321cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0206_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "605a0002-6cb0-40cb-8cea-7cf31d8ee2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3648797"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0206_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1ace7008-af9d-4c2a-bb47-8018808a2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0206_extracted_input_features.npy\", blk_0206_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1c589121-eea7-4a8a-8b5e-4a9fe716199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a65107c0-0970-49e2-8735-a8a7630637bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "CPU times: user 2.53 s, sys: 119 ms, total: 2.65 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0206_targets = []\n",
    "for file in blk_0206_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0206_data_path)\n",
    "    blk_0206_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6ad25d02-342a-46a9-a51e-a112ed2f1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0206_stacked_extracted_targets = np.stack(blk_0206_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "98726a79-c809-4681-8a77-87a007354bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0206_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ea81f9a8-5cd0-494c-a7b9-f1248cfcc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0206_extracted_target_features.npy\", blk_0206_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03228ada-c86a-4e75-b078-7c3b11a67a5f",
   "metadata": {},
   "source": [
    "Block 0302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c6dfe8f-9046-4956-83b7-148d16729f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0302_data_path = '../../Spring_2024/S_lab_TasselNet/Block_14_TN/Block_14_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a3917ed1-d446-4cb1-b4cb-d2f33bd3f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0302_horizontal_images = get_horizontal_images(blk_0302_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2bf5e290-a791-4c9a-a754-f6ad756a688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0302_input_time_point_images = blk_0302_horizontal_images[:13]\n",
    "blk_0302_input_time_point_images.sort()\n",
    "blk_0302_output_time_point_images = blk_0302_horizontal_images[-7:]\n",
    "blk_0302_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fcd9911c-5c79-46cb-add8-3a115d2dcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0302_input_time_point_images, blk_0302_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e1456119-7942-4fb7-b6e1-a24f3a6194a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.53 s, sys: 250 ms, total: 4.78 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0302_alt_all_features = []\n",
    "for file in blk_0302_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0302_data_path)\n",
    "    blk_0302_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bde8918c-452c-4ed1-8530-aaeb34487829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0302_stacked_extracted_input_features = np.stack(blk_0302_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bc8d4288-c235-497c-bdca-6dbc36deab6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0302_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b51a3df5-1fac-4e10-bc35-78acf0a54e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34874612"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0302_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "30b67410-c51b-4d42-994c-7c8c13e752a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0302_extracted_input_features.npy\", blk_0302_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "52070584-9164-45a2-a6b8-af5e05cebe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bb50aaa0-1c90-4ba3-ab0a-90b8fbc1ec96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.47 s, sys: 144 ms, total: 2.61 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0302_targets = []\n",
    "for file in blk_0302_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0302_data_path)\n",
    "    blk_0302_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2367c9f6-716d-47bb-969f-1d3271740eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0302_stacked_extracted_targets = np.stack(blk_0302_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2efa7bb1-0e18-4cd6-921c-85a9e2ab5295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0302_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f467bc55-e307-4ccd-8e69-ff498b03ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0302_extracted_target_features.npy\", blk_0302_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6cc506-b3c3-4950-b6aa-7d64d969ea27",
   "metadata": {},
   "source": [
    "Block 0303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cee0dba1-cd29-43c0-89b4-71990e35a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0303_data_path = '../../Spring_2024/S_lab_TasselNet/Block_15_TN/Block_15_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a8d2ee04-aa85-4e1a-a656-acc9bbf1f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0303_horizontal_images = get_horizontal_images(blk_0303_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "97a8dd7b-94df-48cf-9267-7870b14a99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0303_input_time_point_images = blk_0303_horizontal_images[:13]\n",
    "blk_0303_input_time_point_images.sort()\n",
    "blk_0303_output_time_point_images = blk_0303_horizontal_images[-7:]\n",
    "blk_0303_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f2366fc8-c3cc-4ced-a8d2-c7a866565862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0303_input_time_point_images, blk_0303_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a58030f8-dee8-4211-9171-66c17c1baf17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.51 s, sys: 254 ms, total: 4.76 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0303_alt_all_features = []\n",
    "for file in blk_0303_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0303_data_path)\n",
    "    blk_0303_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cf940cae-2504-4e48-99bc-8c203e3bee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0303_stacked_extracted_input_features = np.stack(blk_0303_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "873c69b8-c6d8-4f65-9e33-aea9efec6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0303_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2a2e4a89-fcaa-4b98-bf23-d21f5f721479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35397637"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0303_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2d0abe80-7a65-4866-826d-a774454de63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0303_extracted_input_features.npy\", blk_0303_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "274ff227-8364-48b8-931c-ee533c667434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1deaa99e-89ad-4d97-bca7-6163a3638ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.47 s, sys: 138 ms, total: 2.61 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0303_targets = []\n",
    "for file in blk_0303_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0303_data_path)\n",
    "    blk_0303_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7e27280c-40c1-436d-849e-0ed9b2a7423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0303_stacked_extracted_targets = np.stack(blk_0303_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2705ec35-7198-4436-bc68-71e574153f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0303_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6fe9be1b-5657-48c2-b519-78200a69ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0303_extracted_target_features.npy\", blk_0303_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328108fe-ea52-40c4-99ef-66d59daa6cc5",
   "metadata": {},
   "source": [
    "Block 0304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "69f65ef3-1579-4a50-af01-09d72adbca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0304_data_path = '../../Spring_2024/S_lab_TasselNet/Block_16_TN/Block_16_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "eba8df78-9211-4b6e-8af8-4fc059910c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0304_horizontal_images = get_horizontal_images(blk_0304_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4c85c37a-de9d-497e-b177-9db3afed5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0304_input_time_point_images = blk_0304_horizontal_images[:13]\n",
    "blk_0304_input_time_point_images.sort()\n",
    "blk_0304_output_time_point_images = blk_0304_horizontal_images[-7:]\n",
    "blk_0304_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0f09fa9b-33d7-454b-bf00-a8b4718890b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0304_input_time_point_images, blk_0304_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "756a117f-05a1-496a-a95b-5c15504636a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.63 s, sys: 199 ms, total: 4.83 s\n",
      "Wall time: 4.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0304_alt_all_features = []\n",
    "for file in blk_0304_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0304_data_path)\n",
    "    blk_0304_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e18238d6-ebc3-4e73-9598-7656795d969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0304_stacked_extracted_input_features = np.stack(blk_0304_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "38b6973e-2bdc-4428-996e-1f824610324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0304_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "285059a5-86ea-4074-9dab-9274e2f02304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3712321"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0304_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3e7ff299-e98e-492f-b93e-1f045dbfacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0304_extracted_input_features.npy\", blk_0304_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ba91d9cc-769e-4ccb-9cc7-dea3cda42d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c2966e51-af1f-4191-85c2-befbbeb6a022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.59 s, sys: 110 ms, total: 2.7 s\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0304_targets = []\n",
    "for file in blk_0304_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0304_data_path)\n",
    "    blk_0304_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "60656fd0-3361-4b9f-bf72-6eae46273fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0304_stacked_extracted_targets = np.stack(blk_0304_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "844bf373-dd06-42d5-9052-d101184e284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0304_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "396a94f4-71e4-4104-b44a-3fdc8196cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0304_extracted_target_features.npy\", blk_0304_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4ccda-abd7-4e1a-abc1-b6956fbf9b03",
   "metadata": {},
   "source": [
    "Block 0305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f597a2e6-5eef-49b7-8753-c9208ea07125",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0305_data_path = '../../Spring_2024/S_lab_TasselNet/Block_17_TN/Block_17_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3607f687-1a9a-4037-8ea4-2833fa6f2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0305_horizontal_images = get_horizontal_images(blk_0305_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c62e73d8-3a4a-4989-ab94-ec093327544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0305_input_time_point_images = blk_0305_horizontal_images[:13]\n",
    "blk_0305_input_time_point_images.sort()\n",
    "blk_0305_output_time_point_images = blk_0305_horizontal_images[-7:]\n",
    "blk_0305_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d8de65fb-3261-4568-9a9c-6d7a8628a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0305_input_time_point_images, blk_0305_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "827aea6d-6d8a-4b3a-a1d5-e9fa459e761f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.7 s, sys: 207 ms, total: 4.91 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0305_alt_all_features = []\n",
    "for file in blk_0305_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0305_data_path)\n",
    "    blk_0305_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8f38c49d-a7e1-4809-a4ac-55bf782c22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0305_stacked_extracted_input_features = np.stack(blk_0305_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5c480e5c-2869-4ab2-8e47-db15fc9898f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0305_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "77d4cfd6-9a5c-4c93-95ec-26c0b4ab83d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3665945"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0305_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d516035-458a-482e-9788-e6d87a6e1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0305_extracted_input_features.npy\", blk_0305_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0c9c5a79-db26-4cd7-84b1-89849394fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4a731a04-d087-41f0-bbc7-2d7a52810219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.52 s, sys: 127 ms, total: 2.64 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0305_targets = []\n",
    "for file in blk_0305_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0305_data_path)\n",
    "    blk_0305_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "689e250d-7382-42e6-9445-623c96ee4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0305_stacked_extracted_targets = np.stack(blk_0305_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ba2981ae-4a9c-4e5b-a073-bd0301027c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0305_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f49f19a9-3140-489a-b4f7-c1a9ab8777da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0305_extracted_target_features.npy\", blk_0305_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fb84f-ed01-4c54-98de-5f59f2460bd1",
   "metadata": {},
   "source": [
    "Block 0306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7bf99c19-2d24-43b9-af76-41b6ba6a680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0306_data_path = '../../Spring_2024/S_lab_TasselNet/Block_18_TN/Block_18_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a795604e-4e3f-440b-a0fb-e4ac6aa8be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0306_horizontal_images = get_horizontal_images(blk_0306_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "71a70f60-effc-4f08-afd5-1fccc4c626b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0306_input_time_point_images = blk_0306_horizontal_images[:13]\n",
    "blk_0306_input_time_point_images.sort()\n",
    "blk_0306_output_time_point_images = blk_0306_horizontal_images[-7:]\n",
    "blk_0306_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0a2d2883-10ce-428b-a4d2-1e3b2db1dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0306_input_time_point_images, blk_0306_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b93d6012-6257-4f34-ac3b-c1a9105b6fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.61 s, sys: 208 ms, total: 4.82 s\n",
      "Wall time: 4.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0306_alt_all_features = []\n",
    "for file in blk_0306_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0306_data_path)\n",
    "    blk_0306_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1de9ef43-e5bf-4c3e-938b-1fd31a9db3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0306_stacked_extracted_input_features = np.stack(blk_0306_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fafc7c8c-88e3-4c7b-8b8d-d14cce55a4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0306_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a1e13cd6-243a-4411-9c17-806107e181a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36130017"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0306_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b5ebd511-69e9-4d76-859e-3ca355f7bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_test_data/block_0306_extracted_input_features.npy\", blk_0306_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "56f19671-fc30-470c-9b2f-93b205e8bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c89e534b-c641-4297-888a-e23352f4c975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "CPU times: user 2.53 s, sys: 135 ms, total: 2.66 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0306_targets = []\n",
    "for file in blk_0306_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0306_data_path)\n",
    "    blk_0306_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b0fda7d6-ede0-49e7-b6b8-8c0144222d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0306_stacked_extracted_targets = np.stack(blk_0306_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "88ef4565-34ef-470f-a670-3d6eab5602f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0306_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2c060cb5-f6e2-448d-92c1-585a522155eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_test_data/block_0306_extracted_target_features.npy\", blk_0306_stacked_extracted_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
