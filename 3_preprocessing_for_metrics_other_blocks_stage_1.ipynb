{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cc1f0d-af14-41fd-85e6-a0a75ff8696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 12:54:20.918057: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 12:54:21.279775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 12:54:21.279846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 12:54:21.362841: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 12:54:21.478643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e9d312-d031-4982-b108-df77c58da122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the previous work, we have the following functions that we have written "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42b02d5-0ada-42ae-aff8-b13f010be82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for extracting onlt the horizontal images out of all the files in the location\n",
    "\n",
    "def get_horizontal_images(file_path):\n",
    "    # get all contents at the file path\n",
    "    all_files = os.listdir(file_path)\n",
    "    # get only the image files as we do not need the xml files for the seq2seq model\n",
    "    only_images = [file for file in all_files if file.split(\".\")[-1] == 'jpeg']\n",
    "    # from all the images only choose the horizontal ones\n",
    "    horizontal_images = [file for file in only_images if file.split('.')[0][-10:] in horizontal_image_list]\n",
    "    # sort the list\n",
    "    horizontal_images.sort()\n",
    "    # return the image list\n",
    "    return horizontal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fd944a-2d59-4bf2-9a4e-6797b6670e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_windows_and_extract_features(folder_path, file, stride = 32, kernel_size = 32):\n",
    "    # joined image path\n",
    "    joined_im_path = os.path.join(folder_path, file)\n",
    "    # read the image\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "    # create subwindows and get prediction\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "\n",
    "    # catch alle extracted features here\n",
    "    all_extracted_features = []\n",
    "    # you can also keep track the subwindows here if required - but let's not worry about that for now\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (kernel_size, kernel_size,3))\n",
    "            # expand the dimension of the window to get predictions from the feature extractor - (make subwindows from shape (32,32,3) to\n",
    "            # (1,32,32,3))\n",
    "            sub_window = np.expand_dims(sub_window, axis = 0)\n",
    "            # extract the features\n",
    "            predicted_features = feature_extractor_model.predict(sub_window)\n",
    "            # append the extracted features\n",
    "            all_extracted_features.append(predicted_features)\n",
    "\n",
    "    return all_extracted_features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb036bde-445a-4eb5-9eeb-a4d87060a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images we use in the task are in the following list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf37b311-2de4-4d1f-b41a-593c43d826d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_image_list = ['2020_08_03', '2020_08_04', '2020_08_06', '2020_08_07', '2020_08_11', '2020_08_12', '2020_08_14', '2020_08_15', '2020_08_17', '2020_08_18', '2020_08_19', '2020_08_21', '2020_08_25', '2020_08_26', '2020_08_27', '2020_08_28', '2020_08_31', '2020_09_02', '2020_09_07', '2020_09_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49252a86-1f60-4eab-bd9a-197b5fd5d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need the fine-tuned model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7e5efe-ed35-4783-b4f9-a00f71172e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 12:54:34.444194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# load the finetuned gmp model\n",
    "gmp_model = tf.keras.models.load_model('../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd433550-20ff-49f1-a45f-bc4f21fe5f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cae73bc-7f5e-4a02-ab56-11cbb729180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature extractor\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = gmp_model.input\n",
    "\n",
    "# feature extractor output - do this at the ReLu activation layer - as this will give the same features as the dropout layer (It does not matter if it is the dropout or the activation layer, the extracted features will be the same)\n",
    "feat_ext_output = gmp_model.layers[-4].output\n",
    "\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8fffb9-60e8-4bd3-9428-7993e40f543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bca3fb-a46c-43c2-a979-e9a68169e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to preprocess all the data for the rest of the blocks, for the task of prediction and performance evaluation.\n",
    "\n",
    "# The problem we currently have is the written code takes up a lot of time. -It takes too much time to do the feature extraction. Currently we are using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc191f2-b001-405e-89ed-8b1d5f6c6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, let's try and solve this problem with the first block in the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb4b4c2-7151-4b3b-bbe4-2482f727752c",
   "metadata": {},
   "source": [
    "Block 0103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e20dd6-39be-4348-b4dd-2a8fe42932d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0103_data_path = '../../Spring_2024/S_lab_TasselNet/Block_3_TN/Block_3_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0db5226-0f08-4c87-accf-acc2a5c871c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0103_horizontal_images = get_horizontal_images(blk_0103_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd10d3fd-cf76-4b0f-a64e-092756c67673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0103_input_time_point_images = blk_0103_horizontal_images[:13]\n",
    "blk_0103_input_time_point_images.sort()\n",
    "blk_0103_output_time_point_images = blk_0103_horizontal_images[-7:]\n",
    "blk_0103_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6fe5c69-8b34-4d94-9df6-f91d603ff818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0103_input_time_point_images, blk_0103_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa3da01-fb04-46e8-a577-3842d95c1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now we need to modify the next function a little to see if the timing for the computations can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ae7e35e-105c-40c0-9877-441faf55de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we first stack the subwindows in a function, and then do model.predict may be in a separate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2007374-3de7-442f-85c2-f84f90083b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_windows(folder_path, file, stride = 30, kernel_size = 30):\n",
    "    # joined image path\n",
    "    joined_im_path = os.path.join(folder_path, file)\n",
    "    # read the image\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "    # create subwindows and get prediction\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "\n",
    "    # catch all subwindows here\n",
    "    all_subwindows = []\n",
    "    # you can also keep track the subwindows here if required - but let's not worry about that for now\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (kernel_size, kernel_size,3))\n",
    "            # append these to the list\n",
    "            all_subwindows.append(sub_window)\n",
    "            \n",
    "    return all_subwindows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0314e666-50c9-49ea-9fdd-37838ec47594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10835ae1-cf8b-4ccf-b0f5-70017f5b12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_0 = blk_0103_input_time_point_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ffd49c6-6a87-49aa-8789-0f5aca821309",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_0_sub_windows = create_sub_windows(blk_0103_data_path, test_image_0, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "969aed4e-ab6b-4cf5-a3ea-aa0b0039f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to stack the list\n",
    "test_image_0_sub_windows_stack = np.stack(test_image_0_sub_windows, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "701d9165-0d9d-49a6-b9fe-9d9186f8d18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 30, 30, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_0_sub_windows_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eacf764-9a45-4599-9f02-44aebea398f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 12:54:35.650224: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 6ms/step\n",
      "CPU times: user 689 ms, sys: 217 ms, total: 906 ms\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# try model.predict with this\n",
    "test_image_0_extracted_features = feature_extractor_model.predict(test_image_0_sub_windows_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80a00704-ae43-4b64-8670-8653877dbad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_0_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24b5d686-7e20-47d2-a7e6-dea7ce10ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so this happense pretty fast (in 2 seconds as opposed to 42 secods - so we do have a huge improvemet in execution time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "379d423b-433f-4a78-b46d-723c6815f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try doing this for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "939110c4-9a5b-4bc5-80d4-6ae3b8299b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0103_2020_08_03.jpeg',\n",
       " 'Block0103_2020_08_04.jpeg',\n",
       " 'Block0103_2020_08_06.jpeg',\n",
       " 'Block0103_2020_08_07.jpeg',\n",
       " 'Block0103_2020_08_11.jpeg',\n",
       " 'Block0103_2020_08_12.jpeg',\n",
       " 'Block0103_2020_08_14.jpeg',\n",
       " 'Block0103_2020_08_15.jpeg',\n",
       " 'Block0103_2020_08_17.jpeg',\n",
       " 'Block0103_2020_08_18.jpeg',\n",
       " 'Block0103_2020_08_19.jpeg',\n",
       " 'Block0103_2020_08_21.jpeg',\n",
       " 'Block0103_2020_08_25.jpeg']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input features for block 0103\n",
    "blk_0103_input_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f3faac-8820-42e9-a2a8-e442b4c2cfc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.46 s, sys: 148 ms, total: 4.61 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "block_0103_extracted_features = []\n",
    "for file in blk_0103_input_time_point_images:\n",
    "    # get the subwindows\n",
    "    subwindows = create_sub_windows(blk_0103_data_path, file, 30, 30)\n",
    "    # stack the subwindows\n",
    "    stacked_subwindows = np.stack(subwindows, axis = 0)\n",
    "    # print the shape of this\n",
    "    print(stacked_subwindows.shape)\n",
    "    # extract features\n",
    "    extracted_featrues = feature_extractor_model.predict(stacked_subwindows)\n",
    "    # append the extracted features\n",
    "    block_0103_extracted_features.append(extracted_featrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccfd181f-e079-4427-be41-aa692eb0f253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_0103_extracted_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1f0e502-58f4-4ba3-bbb2-1a70c4d931e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now stack all these together?\n",
    "blk_0103_stacked_input_features = np.stack(block_0103_extracted_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46ebe1a3-badc-47d9-ac2f-41e77b4c4350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0103_stacked_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ded613d-e6ef-41fa-a56f-0df51723608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, this seems to work really fast - better!\n",
    "# now what if we do a function to get the predictions (extracted features too) - this would be easy for the rest of the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427af14c-5bec-4b46-bb53-106127a59eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d94c2-834b-457e-8bd5-625736310f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3c420-10ba-40cc-9b35-ffac3a4a5a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0b1e7-1aa6-40e7-aace-432a34f61df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb4e7d-230a-4487-90bd-32200e23b55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde19f12-87a9-422b-9033-c80ac1fa84e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16fb9989-9e05-4301-9bd7-2cdbf4465ce1",
   "metadata": {},
   "source": [
    "#### WE NEED MORE SANITY CHECKS TO ENSURE WE ARE STACKING THE MATRICES CORRECTLY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46636373-e850-4b35-af58-16cfd81e2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sanity check maybe use the already created and store np stacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
