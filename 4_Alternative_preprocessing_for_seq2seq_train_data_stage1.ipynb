{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f885ea67-f75e-4d4a-ae27-be4881d16adf",
   "metadata": {},
   "source": [
    "Okay, we need to do sanity check to make sure that we have implemented the functions in the notebook \"3_preprocessing_for_metrics_other_blocks_stage_1.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501e361-150a-4950-8348-7ed15683a50c",
   "metadata": {},
   "source": [
    "The easiest way to verify this is to use these functions on the train data (that was preprocessed using the notebook \"1_preprocessing_for_seq_2_seq_stage_1.ipynb\"), preprocess the data using the new functions and make sure the np arrays stored using the two methods is excatly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5c1e9-6d50-48ea-98da-25d0ba06900f",
   "metadata": {},
   "source": [
    "Paste below the required codes for the functions and the model to extract features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae48d5-0dec-46ed-84d5-e1e1ca202c68",
   "metadata": {},
   "source": [
    "##### This mehtod is much fater than what was done in the \"1_preprocessing_for_seq_2_seq_stage_1.ipynb\" notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a38ebf-d8fe-4717-a592-7c1d94541439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 19:42:40.011858: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 19:42:40.337403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 19:42:40.337464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 19:42:40.407685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 19:42:40.515184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676cd416-0eee-485d-9ba1-4317dbaa5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 19:42:50.270507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30310 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# load the finetuned gmp model\n",
    "gmp_model = tf.keras.models.load_model('../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ce26b8-d92b-417f-b283-f3466c5d1c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gmp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af87b41-0de0-4868-8431-5b9e621abb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature extractor\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = gmp_model.input\n",
    "\n",
    "# feature extractor output - do this at the ReLu activation layer - as this will give the same features as the dropout layer (It does not matter if it is the dropout or the activation layer, the extracted features will be the same)\n",
    "feat_ext_output = gmp_model.layers[-4].output\n",
    "\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f33ebfb-01ef-40c9-979a-643f5bf1d978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c73422f-d74b-4947-8002-ede9312849b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for extracting onlt the horizontal images out of all the files in the location\n",
    "\n",
    "def get_horizontal_images(file_path):\n",
    "    # get all contents at the file path\n",
    "    all_files = os.listdir(file_path)\n",
    "    # get only the image files as we do not need the xml files for the seq2seq model\n",
    "    only_images = [file for file in all_files if file.split(\".\")[-1] == 'jpeg']\n",
    "    # from all the images only choose the horizontal ones\n",
    "    horizontal_images = [file for file in only_images if file.split('.')[0][-10:] in horizontal_image_list]\n",
    "    # sort the list\n",
    "    horizontal_images.sort()\n",
    "    # return the image list\n",
    "    return horizontal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a037846-28a5-4139-980a-177bc4514c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following alternate functions are written to improve the execution time of the prediction from the model to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d5dfb3-6b32-423b-aae3-d6d76ffa690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_windows(folder_path, file, stride = 30, kernel_size = 30):\n",
    "    # joined image path\n",
    "    joined_im_path = os.path.join(folder_path, file)\n",
    "    # read the image\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "    # create subwindows and get prediction\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "\n",
    "    # catch all subwindows here\n",
    "    all_subwindows = []\n",
    "    # you can also keep track the subwindows here if required - but let's not worry about that for now\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (kernel_size, kernel_size,3))\n",
    "            # append these to the list\n",
    "            all_subwindows.append(sub_window)\n",
    "            \n",
    "    return all_subwindows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c937ae48-d32c-4b65-bf55-5a9f0012c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name, file_path):\n",
    "    # get the subwindows\n",
    "    subwindows = create_sub_windows(file_path, file_name, 30, 30)\n",
    "    # stack the subwindows\n",
    "    stacked_subwindows = np.stack(subwindows, axis = 0)\n",
    "    # print the shape of this\n",
    "    print(stacked_subwindows.shape)\n",
    "    # extract features\n",
    "    extracted_featrues = feature_extractor_model.predict(stacked_subwindows)\n",
    "    \n",
    "    return extracted_featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78165ddf-a9df-452d-b28a-bb20071644f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_image_list = ['2020_08_03', '2020_08_04', '2020_08_06', '2020_08_07', '2020_08_11', '2020_08_12', '2020_08_14', '2020_08_15', '2020_08_17', '2020_08_18', '2020_08_19', '2020_08_21', '2020_08_25', '2020_08_26', '2020_08_27', '2020_08_28', '2020_08_31', '2020_09_02', '2020_09_07', '2020_09_16']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6e5ec-a3bd-48dd-a0f3-8dbacf15a4b0",
   "metadata": {},
   "source": [
    "Block 0101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238496d3-3318-40ed-9339-8d622302d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0101_data_path = '../../Spring_2024/S_lab_TasselNet/Block_1_TN/Block_1_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5f4e45-7f6b-492f-ab55-6e0f3751e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0101_horizontal_images = get_horizontal_images(blk_0101_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7f81d7-bb22-4d9c-b423-22dd003e5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0101_input_time_point_images = blk_0101_horizontal_images[:13]\n",
    "blk_0101_input_time_point_images.sort()\n",
    "blk_0101_output_time_point_images = blk_0101_horizontal_images[-7:]\n",
    "blk_0101_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a2919b7-0bff-4c48-b5c9-375992fc8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0101_input_time_point_images, blk_0101_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e248dcc3-f457-4453-bd69-2dcdeecdd720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 19:42:51.455162: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 5ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.99 s, sys: 507 ms, total: 5.5 s\n",
      "Wall time: 6.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0101_alt_all_features = []\n",
    "for file in blk_0101_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0101_data_path)\n",
    "    blk_0101_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b602eea5-45c3-451c-94bf-493f2031fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0101_stacked_extracted_input_features = np.stack(blk_0101_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6141e95-e226-4b13-afce-72b591e63225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0101_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca747017-9fa1-4795-84df-4c360940bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3515611"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0101_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cba931f2-86f7-48f6-af6a-0c89e8143a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_train_data_alt/block_0101_extracted_input_features.npy\", blk_0101_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98cd4398-35ab-4392-ba1a-2c31478d1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae22401a-b92d-4b29-865a-522275200fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.38 s, sys: 138 ms, total: 2.52 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0101_targets = []\n",
    "for file in blk_0101_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0101_data_path)\n",
    "    blk_0101_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ecd787c-2f7c-4362-97b9-7dab73e52061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0101_stacked_extracted_targets = np.stack(blk_0101_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63c45eea-e0d3-4f7d-a5a0-bb461900f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0101_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f55c0675-f90f-4013-b0f7-ec631da389db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_train_data_alt/block_0101_extracted_target_features.npy\", blk_0101_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74e6a91a-de79-4f47-82aa-1a816e8b611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these values are the same\n",
    "# load the previously stored np values\n",
    "\n",
    "all_train_data_previously_preprocessed = os.listdir(\"seq_2_seq_train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a1dec04-f1c6-4c70-9c03-592130cf849e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block_0101_extracted_input_features.npy',\n",
       " 'block_0101_extracted_target_features.npy',\n",
       " 'block_0102_extracted_input_features.npy',\n",
       " 'block_0102_extracted_target_features.npy',\n",
       " 'block_0203_extracted_input_features.npy',\n",
       " 'block_0203_extracted_target_features.npy',\n",
       " 'block_0301_extracted_input_features.npy',\n",
       " 'block_0301_extracted_target_features.npy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data_previously_preprocessed.sort()\n",
    "all_train_data_previously_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1751c61e-dced-401f-ba31-eb2b9fdf412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these data\n",
    "alt_0101_input_features = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0101_extracted_input_features.npy\"))\n",
    "alt_0101_targets = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0101_extracted_target_features.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae77e37b-f2d2-4809-8112-9602ee38d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999445266272189\n",
      "0.9999607535321821\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.round(blk_0101_stacked_extracted_input_features, 3) == np.round(alt_0101_input_features,3)))\n",
    "print(np.mean(np.round(blk_0101_stacked_extracted_targets,3) == np.round(alt_0101_targets,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef55984c-1b37-47d9-8252-024b05724f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3515611, 0.3515611)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0101_stacked_extracted_input_features), np.mean(alt_0101_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2473bc8b-b474-42fd-a342-2649139a4999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36970586, 0.36970586)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0101_stacked_extracted_targets), np.mean(alt_0101_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa572a00-7925-483f-b88c-7ec1832f6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems they are correct, do this for the rest of the train data as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab2bed-72db-415f-bb23-0920229a6ce5",
   "metadata": {},
   "source": [
    "Block 0102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51fd5bb3-a867-4ce4-a17f-32a3f67141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0102_data_path = '../../Spring_2024/S_lab_TasselNet/Block_2_TN/Block_2_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dff9871c-607d-4a9f-bcca-1c3264ba62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0102_horizontal_images = get_horizontal_images(blk_0102_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7978b760-dc06-4002-8833-c164f95fa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0102_input_time_point_images = blk_0102_horizontal_images[:13]\n",
    "blk_0102_input_time_point_images.sort()\n",
    "blk_0102_output_time_point_images = blk_0102_horizontal_images[-7:]\n",
    "blk_0102_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "660cb312-fd76-42f5-b302-dcb2f4076f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0102_input_time_point_images, blk_0102_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d472685-64c9-44e2-9a99-88f66097dbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.44 s, sys: 261 ms, total: 4.7 s\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0102_alt_all_features = []\n",
    "for file in blk_0102_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0102_data_path)\n",
    "    blk_0102_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d145e730-1d8f-47fc-af97-60e647aabc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0102_stacked_extracted_input_features = np.stack(blk_0102_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8fc5a3-3aa2-49e2-925f-155e4cc96657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0102_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "423b82de-1955-4308-aaac-289456c9ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35029814"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0102_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e654c360-be1c-4e38-b19f-65dce7c55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_train_data_alt/block_0102_extracted_input_features.npy\", blk_0102_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7053f07a-3a8e-45c2-9f51-72ba9b6fd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "482e105e-0548-4e1f-a069-83615a7abebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.4 s, sys: 80.1 ms, total: 2.48 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0102_targets = []\n",
    "for file in blk_0102_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0102_data_path)\n",
    "    blk_0102_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23c46e4d-1a1b-4032-88b7-f0667f34149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0102_stacked_extracted_targets = np.stack(blk_0102_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5352815c-73eb-405d-9007-97af9014246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0102_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f612d90d-f65a-49cf-b1f1-6b799a9b96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_train_data_alt/block_0102_extracted_target_features.npy\", blk_0102_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a71ff274-5303-480b-8c8e-578ba6a89736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these data\n",
    "alt_0102_input_features = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0102_extracted_input_features.npy\"))\n",
    "alt_0102_targets = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0102_extracted_target_features.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1d54857-3fb1-47d2-a742-c9c62d690f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999947168216399\n",
      "0.9999460361067504\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.round(blk_0102_stacked_extracted_input_features, 3) == np.round(alt_0102_input_features,3)))\n",
    "print(np.mean(np.round(blk_0102_stacked_extracted_targets,3) == np.round(alt_0102_targets,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba71e79b-ee42-4862-80c1-43b70253174f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35029814, 0.35029814)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0102_stacked_extracted_input_features), np.mean(alt_0102_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be807d76-b5c3-4690-bcc3-a82907c2c50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3753665, 0.37536648)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0102_stacked_extracted_targets), np.mean(alt_0102_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a82ff-72cd-4c1b-a5c6-03f3b772531d",
   "metadata": {},
   "source": [
    "Block 0203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b741b0fe-c9c1-4eb9-8e03-2fd162e3ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0203_data_path = '../../Spring_2024/S_lab_TasselNet/Block_9_TN/Block_9_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fd76927-f161-465b-9be5-a13cce3a7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0203_horizontal_images = get_horizontal_images(blk_0203_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65b5d782-d3f7-415f-a8ba-386796799eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0203_input_time_point_images = blk_0203_horizontal_images[:13]\n",
    "blk_0203_input_time_point_images.sort()\n",
    "blk_0203_output_time_point_images = blk_0203_horizontal_images[-7:]\n",
    "blk_0203_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a8b1c0f-8813-4ab7-90df-b50dbce902e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0203_input_time_point_images, blk_0203_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26a9d929-b794-46f3-bce9-39f264911a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.43 s, sys: 204 ms, total: 4.63 s\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0203_alt_all_features = []\n",
    "for file in blk_0203_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0203_data_path)\n",
    "    blk_0203_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3aec1c89-fdc2-49e1-9d50-6477b0a46799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0203_stacked_extracted_input_features = np.stack(blk_0203_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c5f7950-c049-4090-85dd-175685592bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0203_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "223e9847-c1f2-4177-a7ae-d574161c73cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34053323"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0203_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51072b86-7374-4df8-a097-f529f6859650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_train_data_alt/block_0203_extracted_input_features.npy\", blk_0203_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8185d127-7399-4e67-82cf-6256f55eafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "740b4b83-69de-4b08-8993-708a962082fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.39 s, sys: 123 ms, total: 2.51 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0203_targets = []\n",
    "for file in blk_0203_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0203_data_path)\n",
    "    blk_0203_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ab188ea-3b9d-4bc1-952b-7b4273f011b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0203_stacked_extracted_targets = np.stack(blk_0203_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "421e788e-68d8-4761-b9df-2f9dbaf52e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0203_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3913bd83-2e4f-4bd3-90e9-994f8ecb8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_train_data_alt/block_0203_extracted_target_features.npy\", blk_0203_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d9b0814-2f74-4199-b341-872bba6253c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these data\n",
    "alt_0203_input_features = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0203_extracted_input_features.npy\"))\n",
    "alt_0203_targets = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0203_extracted_target_features.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47895252-a5f8-4f00-8893-2e97afcf074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999207523245984\n",
      "0.999916601255887\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.round(blk_0203_stacked_extracted_input_features, 3) == np.round(alt_0203_input_features,3)))\n",
    "print(np.mean(np.round(blk_0203_stacked_extracted_targets,3) == np.round(alt_0203_targets,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "046db18e-db54-4cb8-b4a8-7746eb62c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34053323, 0.3405332)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0203_stacked_extracted_input_features), np.mean(alt_0203_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56b4cdab-53af-4e5a-8a25-a0429621f3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33241686, 0.33241686)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0203_stacked_extracted_targets), np.mean(alt_0203_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305759e-558f-44fb-9bd7-f18276be5fa7",
   "metadata": {},
   "source": [
    "Block 0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81420ed0-71fe-4bc3-9e8c-e7f8417615c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0301_data_path = '../../Spring_2024/S_lab_TasselNet/Block_13_TN/Block_13_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b07a790c-49ad-4bf6-9495-7566ec507eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0301_horizontal_images = get_horizontal_images(blk_0301_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50104708-7096-4127-8451-730f05c405a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0301_input_time_point_images = blk_0301_horizontal_images[:13]\n",
    "blk_0301_input_time_point_images.sort()\n",
    "blk_0301_output_time_point_images = blk_0301_horizontal_images[-7:]\n",
    "blk_0301_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9c50851-885f-4ab9-ac69-718ece571ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0301_input_time_point_images, blk_0301_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d6adaed-0ee7-49ee-b2d9-5d681d78437c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "CPU times: user 4.49 s, sys: 230 ms, total: 4.72 s\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0301_alt_all_features = []\n",
    "for file in blk_0301_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0301_data_path)\n",
    "    blk_0301_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19d270ed-9fa8-4028-a080-96c86322e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0301_stacked_extracted_input_features = np.stack(blk_0301_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0886faef-d552-44a7-8729-9a52d67e6e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0301_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a960c6f-56ad-41f2-860f-3a368ffa0068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36407468"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0301_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9abe8bc7-c3ae-44e4-ba68-005632efd284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_train_data_alt/block_0301_extracted_input_features.npy\", blk_0301_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f94a1fd-ed65-40e4-82e7-c2f8f09a5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fd0552f-9285-4910-abb2-f489034fe5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.59 s, sys: 186 ms, total: 2.78 s\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0301_targets = []\n",
    "for file in blk_0301_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0301_data_path)\n",
    "    blk_0301_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4db97842-037d-45ca-b10e-31e1b4a8c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0301_stacked_extracted_targets = np.stack(blk_0301_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3d98227-5bbf-49f7-88fe-02b1879252b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0301_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef7c1e60-7985-4908-84b9-13350afbe6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_train_data_alt/block_0301_extracted_target_features.npy\", blk_0301_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6dd4028d-c316-47a5-8447-a69dbfb3a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these data\n",
    "alt_0301_input_features = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0301_extracted_input_features.npy\"))\n",
    "alt_0301_targets = np.load(os.path.join(\"seq_2_seq_train_data\", \"block_0301_extracted_target_features.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0f9dffc-be79-4e55-b7b8-bf9d7afe364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999445266272189\n",
      "0.9999215070643642\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.round(blk_0301_stacked_extracted_input_features, 3) == np.round(alt_0301_input_features,3)))\n",
    "print(np.mean(np.round(blk_0301_stacked_extracted_targets,3) == np.round(alt_0301_targets,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56124664-794b-4850-9857-7dac3ec6b4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36407468, 0.36407468)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0301_stacked_extracted_input_features), np.mean(alt_0301_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95ce7f6b-d554-48b0-8265-848918315112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36661348, 0.36661348)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0301_stacked_extracted_targets), np.mean(alt_0301_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4bb7303c-9c5d-4f9c-ba5d-a26e67b46466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should do this for validation data too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6323e-58db-418d-9ff9-930d198b97f1",
   "metadata": {},
   "source": [
    "Block 0204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "908ea6b9-c4b4-4122-b7a3-faae539f279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_0204_data_path = '../../Spring_2024/S_lab_TasselNet/Block_10_TN/Block_10_images_and_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "894eeba8-9f63-4bc6-a1b3-82d842822a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can still use the function above to get the horizontal images\n",
    "blk_0204_horizontal_images = get_horizontal_images(blk_0204_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2de51ca0-727a-4f87-a461-0c99c4615b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the inputs and the targets\n",
    "blk_0204_input_time_point_images = blk_0204_horizontal_images[:13]\n",
    "blk_0204_input_time_point_images.sort()\n",
    "blk_0204_output_time_point_images = blk_0204_horizontal_images[-7:]\n",
    "blk_0204_output_time_point_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a721eca4-c778-4ff9-9666-ee8ad90a2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blk_0204_input_time_point_images, blk_0204_output_time_point_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "752e37c7-86ae-48fd-b6d1-6fecce5d82a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 4.49 s, sys: 162 ms, total: 4.66 s\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0204_alt_all_features = []\n",
    "for file in blk_0204_input_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0204_data_path)\n",
    "    blk_0204_alt_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "092ba3da-39fd-4eb4-9226-6aae2e9dcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0204_stacked_extracted_input_features = np.stack(blk_0204_alt_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3aba23ec-8e3d-4217-bba0-279d37ae202b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0204_stacked_extracted_input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "180f8575-a1bf-4ce9-81aa-6140c03413d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3899464"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if mean matches\n",
    "np.mean(blk_0204_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f54001d9-6fbd-4eeb-a0ed-690ee6958be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack? \n",
    "np.save(\"seq_2_seq_valid_data_alt/block_0204_extracted_input_features.npy\", blk_0204_stacked_extracted_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a72b18f-4c1b-4c22-bc65-c9fa518ed370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95463e78-d174-43f2-8f3b-6d1eaae22152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.41 s, sys: 94.5 ms, total: 2.5 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted targets\n",
    "\n",
    "blk_0204_targets = []\n",
    "for file in blk_0204_output_time_point_images:\n",
    "    extracted_features = extract_features(file, blk_0204_data_path)\n",
    "    blk_0204_targets.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cb72a8c7-d1ae-43be-815f-852bd6e707bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0204_stacked_extracted_targets = np.stack(blk_0204_targets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10c2521b-49b5-4755-b92a-93731b95f8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0204_stacked_extracted_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4fad7b8f-ea53-43fd-a272-66355883f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this stack\n",
    "np.save(\"seq_2_seq_valid_data_alt/block_0204_extracted_target_features.npy\", blk_0204_stacked_extracted_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d9a32c18-a748-4834-896f-d149c3b07986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these data\n",
    "alt_0204_input_features = np.load(os.path.join(\"seq_2_seq_valid_data\", \"block_0204_extracted_input_features.npy\"))\n",
    "alt_0204_targets = np.load(os.path.join(\"seq_2_seq_valid_data\", \"block_0204_extracted_target_features.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79e1f158-2e6e-426e-9e29-0713aea83506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999418850380389\n",
      "0.9999754709576139\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.round(blk_0204_stacked_extracted_input_features, 3) == np.round(alt_0204_input_features,3)))\n",
    "print(np.mean(np.round(blk_0204_stacked_extracted_targets,3) == np.round(alt_0204_targets,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77c56592-0070-41c0-be74-c0c50b1765dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3899464, 0.38994637)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0204_stacked_extracted_input_features), np.mean(alt_0204_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f5d7c7b-96da-4f9d-ac47-15bdbb114e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36944777, 0.36944777)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(blk_0204_stacked_extracted_targets), np.mean(alt_0204_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
