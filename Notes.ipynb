{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f18cc8-3b9c-4164-b384-ca58ffc8da41",
   "metadata": {},
   "source": [
    "#### Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9c7b1-618c-45cb-b59b-4aff8d24439a",
   "metadata": {},
   "source": [
    "Problem: We have some images in the sequence missing. We have a 2-stage probem. Stage 1 - we use a seq-2-seq model to create the missing images. Stage 2 - We use latent AR process model to get the final densities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b71f1a-d9b0-4fde-a121-7980899342a4",
   "metadata": {},
   "source": [
    "Let's make the notes on preprocessing here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf876f-35c9-4036-8c90-34320369510f",
   "metadata": {},
   "source": [
    "##### Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b46a62-66d1-44aa-86d9-329a2dc2773a",
   "metadata": {},
   "source": [
    "So we do the seq-2-seq model also on the train data we used to fine-tune the tasselnet model on China data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f6427-da61-47c9-a797-e7111c107910",
   "metadata": {},
   "source": [
    "Input seq length is None, 13, 32, and output shape should be None, 7, 32, where none denotes the batch size. Now first for each subwindow, we need to extract the 32 features. How to do this? - We can take the fine-tuned model and do the feature extraction - chop it off before the prediction head. Once we have it, we just have to stack it in the correct dimensions to have the None, 13, 32 shape for the input, and none, 7, 32 for the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3886828-24d4-4e7e-b20c-ba61a4902e23",
   "metadata": {},
   "source": [
    "There's a lot of overlap for the tasks here, maybe need to talk it out with Ghosh? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928cfb16-3862-4465-bdc0-973a0c26c308",
   "metadata": {},
   "source": [
    "Location of the original images and xml files seems to be:\n",
    "\n",
    "block_0101 = '../../S_lab_TasselNet/Block_1_TN/Block_1_images_and_xml' etc etc as these are the ones used in preprocessing. Check if we really need these, or if we can get away with the existing preprocesed data. For thefirst task of finetuning the China model,we should be able to get away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c70048-78b5-4a66-9d7d-06e6f623ab2d",
   "metadata": {},
   "source": [
    "Also, the formal notes accompanying this work is in \"Chapter_2_Dissertaion_Notes\" at overleaf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31ad18-4ea6-47e6-8b4c-77396df02c96",
   "metadata": {},
   "source": [
    "Things to keep in mind:\n",
    "\n",
    "1. The problem we are trying to solve: Some of the images that appear at the end of our sequence are missing. And we currenly assume these are the last 7 images of the sequence (we have 20 horizontal images per block, therefore we are doing a 13-7 split, we can change the splits for the seq-2-seq model if the model performance is too bad).\n",
    "\n",
    "2. For latent AR process model, we used non-verlapping window sizes of 300, 300, 3 for feature extraction. But if we use this it will be too less data (only 48 as the train sample size, and 12 as the validation sample size), and it will not work well with our DL model.\n",
    "\n",
    "3. Because of this, we will use may be 30, 30, 3 with a stride of 30 - still using overlapping data. Also, since we assume we do not have the later images, we need to be as accurate as possible with the extracted feature prediction, so lowering the window size, and making them overlapped will help (not using overlapping windows currently). \n",
    "\n",
    "4. Train a seq-2-seq model. See if the performance of this model could be improved by changing model architecture, seq-2-seq split (13-7), and overlapping nature, or the sub-window sizes.\n",
    "\n",
    "5. Since we might need to experiment with the above parameters, make sure we right proper functions to quickly change the nature of the data that goes into the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c693c5-a1c3-40c3-9cfb-3d6b204bfa87",
   "metadata": {},
   "source": [
    "The data preprocessing script for train and validation data are in notebook \"1_preprocessing_for_seq_2_seq_stage_1.ipynb\", and the code for traning the seq2seq model is in the notebook \"2_training_seq_2_seq_stage_1.ipynb\". The codes for preprocessing the data for the other blocks (test data) are in the notebook \"3_preprocessing_for_metrics_other_blocks_stage_1.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4a902-58e6-4044-acc4-b9c89ea695de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4417a7-6c87-4d4f-8d0c-b0af49b78a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c769553-7ce8-4e85-8eca-65d01f4c771b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ad06e-57bb-46d7-a0dd-4abbd0d4a3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8390e-957a-4ad1-b674-c6831c179bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_env_01)",
   "language": "python",
   "name": "tfp_env_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
