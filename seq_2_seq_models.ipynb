{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fb265a-93a2-40ac-a66c-34f7765a1774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:04:24.461240: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 17:04:24.943854: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-07 17:04:24.943909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-07 17:04:25.035622: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-07 17:04:25.163645: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39190123-8e52-4fd4-aba7-1e8d430a00cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:04:39.227725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 32)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['input_1[0][0]']             \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59936 (234.12 KB)\n",
      "Trainable params: 59936 (234.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps):\n",
    "    # Input layer for the encoder\n",
    "    inputs = layers.Input(shape=(input_timesteps, input_features))\n",
    "\n",
    "    # Encoder LSTM\n",
    "    encoder = layers.LSTM(64, activation='relu', return_state=True, return_sequences=False)\n",
    "    encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "    # Decoder LSTM: We now provide the encoder's state and initialize it with the encoder's final states\n",
    "    # We reshape the output of the encoder to make sure it is in the expected form for the decoder\n",
    "    decoder_input = layers.RepeatVector(output_timesteps)(encoder_outputs)\n",
    "\n",
    "    # Decoder LSTM, where the output sequence length is `output_timesteps` (7)\n",
    "    decoder_lstm = layers.LSTM(64, activation='relu', return_sequences=True)\n",
    "    decoder_outputs = decoder_lstm(decoder_input, initial_state=[state_h, state_c])\n",
    "\n",
    "    # Dense layer to predict the next 7 time periods (each with 32 features)\n",
    "    outputs = layers.Dense(input_features)(decoder_outputs)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_timesteps = 12  # 12 time periods\n",
    "input_features = 32   # 32 features per time period\n",
    "output_timesteps = 7  # Predict the next 7 time periods\n",
    "\n",
    "# Create the model\n",
    "model = create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5f2bfa-45f4-438b-a7b0-d29d16d6845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:04:43.720094: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c8f5a8bd00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-07 17:04:43.720129: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100S-PCIE-32GB, Compute Capability 7.0\n",
      "2025-04-07 17:04:43.773062: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-07 17:04:43.898852: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744063484.180328 2463858 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 33ms/step - loss: 0.3247\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2693\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1961\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1381\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1071\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0998\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0920\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0887\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0871\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14ca1811f4c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example training data (input and target sequences)\n",
    "import numpy as np\n",
    "\n",
    "# Random input data (batch_size, timesteps, features)\n",
    "X_train = np.random.random((100, input_timesteps, input_features))\n",
    "\n",
    "# Random target data (batch_size, timesteps, features) - predicted next 7 time periods\n",
    "y_train = np.random.random((100, output_timesteps, input_features))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a888b6-ce33-42d4-b74f-a044dd7ff325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 32)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 64),                 24832     ['input_2[0][0]']             \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVec  (None, 7, 64)                0         ['lstm_2[0][0]']              \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 7, 64)                33024     ['repeat_vector_1[0][0]',     \n",
      "                                                                     'lstm_2[0][1]',              \n",
      "                                                                     'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 7, 32)                2080      ['lstm_3[0][0]']              \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59936 (234.12 KB)\n",
      "Trainable params: 59936 (234.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps):\n",
    "    # Input layer for the encoder\n",
    "    inputs = layers.Input(shape=(input_timesteps, input_features))\n",
    "\n",
    "    # Encoder LSTM: Outputs hidden states for each time step in the input sequence\n",
    "    encoder = layers.LSTM(64, activation='relu', return_state=True, return_sequences=False)\n",
    "    encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "    # Decoder LSTM: We will generate output_timesteps (7) future time periods\n",
    "    decoder_input = layers.RepeatVector(output_timesteps)(encoder_outputs)\n",
    "\n",
    "    # Decoder LSTM generates the sequence of 7 time periods\n",
    "    decoder_lstm = layers.LSTM(64, activation='relu', return_sequences=True)\n",
    "    decoder_outputs = decoder_lstm(decoder_input, initial_state=[state_h, state_c])\n",
    "\n",
    "    # TimeDistributed layer to predict 32 features for each of the 7 time periods\n",
    "    time_distributed = layers.TimeDistributed(layers.Dense(input_features))\n",
    "    outputs = time_distributed(decoder_outputs)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_timesteps = 12  # 12 time periods (input sequence)\n",
    "input_features = 32   # 32 features per time period\n",
    "output_timesteps = 7  # Predict the next 7 time periods\n",
    "\n",
    "# Create the model\n",
    "model = create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650489b2-d201-4ebf-a120-61bc3c854e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 12, 32)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(None, 64),                 24832     ['input_3[0][0]']             \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector_2 (RepeatVec  (None, 7, 64)                0         ['lstm_4[0][1]']              \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 7, 64)                33024     ['repeat_vector_2[0][0]',     \n",
      "                                                                     'lstm_4[0][1]',              \n",
      "                                                                     'lstm_4[0][2]']              \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 7, 32)                2080      ['lstm_5[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59936 (234.12 KB)\n",
      "Trainable params: 59936 (234.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps):\n",
    "    # Input layer for the encoder\n",
    "    inputs = layers.Input(shape=(input_timesteps, input_features))\n",
    "\n",
    "    # Encoder LSTM: Outputs the final hidden state (return_sequences=False)\n",
    "    encoder = layers.LSTM(64, activation='relu', return_state=True, return_sequences=False)\n",
    "    encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "    # RepeatVector: Repeat the encoder's final hidden state for `output_timesteps` (7)\n",
    "    decoder_input = layers.RepeatVector(output_timesteps)(state_h)\n",
    "\n",
    "    # Decoder LSTM: Uses the repeated encoder final state and generates output_timesteps future time periods\n",
    "    decoder_lstm = layers.LSTM(64, activation='relu', return_sequences=True)\n",
    "    decoder_outputs = decoder_lstm(decoder_input, initial_state=[state_h, state_c])\n",
    "\n",
    "    # TimeDistributed layer to predict 32 features for each of the 7 time periods\n",
    "    time_distributed = layers.TimeDistributed(layers.Dense(input_features))\n",
    "    outputs = time_distributed(decoder_outputs)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_timesteps = 12  # 12 time periods (input sequence)\n",
    "input_features = 32   # 32 features per time period\n",
    "output_timesteps = 7  # Predict the next 7 time periods\n",
    "\n",
    "# Create the model\n",
    "model = create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83816e-967d-4366-8359-ae5a2454aafd",
   "metadata": {},
   "source": [
    "I think all the three methods are producing the same code, and I think this is correct. We may still need to see if this is correct, or if this needs to be redefned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1c055-555c-453e-a4e6-759685198796",
   "metadata": {},
   "source": [
    "Redefine the code later with correct tf specifications, and I think it should be good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
