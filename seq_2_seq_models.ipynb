{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fb265a-93a2-40ac-a66c-34f7765a1774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 15:49:14.385518: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 15:49:15.450692: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-07 15:49:15.450754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-07 15:49:15.670476: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-07 15:49:15.965296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0150fc8-4083-4778-973e-760b03df623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# define the decoder architecture\u001b[39;00m\n\u001b[1;32m     16\u001b[0m decoder \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m64\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstate_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_c\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define dense layer to predict the next 7 time periods\u001b[39;00m\n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(output_timesteps)(decoder_output)\n",
      "File \u001b[0;32m/common/statsgeneral/gayara/tfp_for_TN/lib/python3.10/site-packages/keras/src/layers/rnn/base_rnn.py:615\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m full_input_spec\n\u001b[0;32m--> 615\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Remove the additional_specs from input spec and keep the rest. It\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# is important to keep since the input spec was populated by\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# build(), and will be reused in the stateful=True.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[0;32m/common/statsgeneral/gayara/tfp_for_TN/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/common/statsgeneral/gayara/tfp_for_TN/lib/python3.10/site-packages/keras/src/initializers/initializers.py:1160\u001b[0m, in \u001b[0;36m_compute_fans\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     fan_in \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m receptive_field_size\n\u001b[1;32m   1159\u001b[0m     fan_out \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m receptive_field_size\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfan_in\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m(fan_out)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "# define the encoder and decoder model\n",
    "\n",
    "# define the necessary time step and input features\n",
    "input_timesteps = 12\n",
    "input_features = 32\n",
    "output_timesteps = 7\n",
    "\n",
    "# define input\n",
    "input_layer = tf.keras.layers.Input(shape = (input_timesteps, input_features))\n",
    "\n",
    "# define the encoder architecture\n",
    "encoder = tf.keras.layers.LSTM(64, activation = 'relu', return_state = True)\n",
    "encoder_output, state_h, state_c = encoder(input_layer)\n",
    "\n",
    "# define the decoder architecture\n",
    "decoder = tf.keras.layers.LSTM(64, activation = 'relu', return_sequences = True)\n",
    "decoder_output = decoder(encoder_output, initial_state=[state_h, state_c])\n",
    "\n",
    "# define dense layer to predict the next 7 time periods\n",
    "outputs =tf.keras.layers.Dense(output_timesteps)(decoder_output)\n",
    "\n",
    "# define the model architecture\n",
    "model = tf.keras.models.Model(input_layer, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0fec575-55ff-4194-9293-d44c9c1b2e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 12, 32)]          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               [(None, 64),              24832     \n",
      "                              (None, 64),                        \n",
      "                              (None, 64)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24832 (97.00 KB)\n",
      "Trainable params: 24832 (97.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5199bdb2-81b6-411b-a386-a7ac55cca4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 12, 32)]             0         []                            \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)       [(None, 7, 32)]              0         []                            \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)              [(None, 64),                 24832     ['input_10[0][0]']            \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)              (None, 7, 64)                24832     ['input_11[0][0]',            \n",
      "                                                                     'lstm_15[0][1]',             \n",
      "                                                                     'lstm_15[0][2]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 7, 32)                2080      ['lstm_16[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51744 (202.12 KB)\n",
      "Trainable params: 51744 (202.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=(input_timesteps, input_features))\n",
    "\n",
    "    # Encoder (LSTM)\n",
    "    encoder = layers.LSTM(64, activation='relu', return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "    # Decoder LSTM with its own input sequence (this part does not use encoder outputs as input)\n",
    "    decoder_inputs = layers.Input(shape=(output_timesteps, input_features))  # Target sequence input\n",
    "    decoder_lstm = layers.LSTM(64, activation='relu', return_sequences=True)\n",
    "    \n",
    "    # Pass encoder states to initialize the decoder LSTM\n",
    "    decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
    "\n",
    "    # Dense layer to predict the next 7 time periods (each with 32 features)\n",
    "    outputs = layers.Dense(input_features)(decoder_outputs)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model([inputs, decoder_inputs], outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_timesteps = 12  # 12 time periods\n",
    "input_features = 32   # 32 features per time period\n",
    "output_timesteps = 7  # Predict the next 7 time periods\n",
    "\n",
    "# Create the model\n",
    "model = create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39190123-8e52-4fd4-aba7-1e8d430a00cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m output_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m  \u001b[38;5;66;03m# Predict the next 7 time periods\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequence_to_sequence_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_timesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Summarize the model\u001b[39;00m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mcreate_sequence_to_sequence_model\u001b[0;34m(input_timesteps, input_features, output_timesteps)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Decoder (LSTM)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m decoder_lstm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstate_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_c\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Dense layer to predict the next 7 time periods (each with 32 features)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(input_features)(decoder_outputs)\n",
      "File \u001b[0;32m/common/statsgeneral/gayara/tfp_for_TN/lib/python3.10/site-packages/keras/src/layers/rnn/base_rnn.py:615\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m full_input_spec\n\u001b[0;32m--> 615\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Remove the additional_specs from input spec and keep the rest. It\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# is important to keep since the input spec was populated by\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# build(), and will be reused in the stateful=True.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[0;32m/common/statsgeneral/gayara/tfp_for_TN/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/common/statsgeneral/gayara/tfp_for_TN/lib/python3.10/site-packages/keras/src/initializers/initializers.py:1160\u001b[0m, in \u001b[0;36m_compute_fans\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     fan_in \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m receptive_field_size\n\u001b[1;32m   1159\u001b[0m     fan_out \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m receptive_field_size\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfan_in\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m(fan_out)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=(input_timesteps, input_features))\n",
    "\n",
    "    # Encoder (LSTM)\n",
    "    encoder = layers.LSTM(64, activation='relu', return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "    # Decoder (LSTM)\n",
    "    decoder_lstm = layers.LSTM(64, activation='relu', return_sequences=True)\n",
    "    decoder_outputs = decoder_lstm(encoder_outputs, initial_state=[state_h, state_c])\n",
    "\n",
    "    # Dense layer to predict the next 7 time periods (each with 32 features)\n",
    "    outputs = layers.Dense(input_features)(decoder_outputs)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the input shape and output shape\n",
    "input_timesteps = 12  # 12 time periods\n",
    "input_features = 32   # 32 features per time period\n",
    "output_timesteps = 7  # Predict the next 7 time periods\n",
    "\n",
    "# Create the model\n",
    "model = create_sequence_to_sequence_model(input_timesteps, input_features, output_timesteps)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f2bfa-45f4-438b-a7b0-d29d16d6845e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa071c-5da5-47de-b3a7-94341248f3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a888b6-ce33-42d4-b74f-a044dd7ff325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_for_TN)",
   "language": "python",
   "name": "tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
